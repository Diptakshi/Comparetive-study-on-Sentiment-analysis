{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SentimentAnalysis_K-means.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvooV5JBaeyM",
        "outputId": "c89e76ce-5362-49ab-ef77-cf26ed528f2a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLQaGzIObcYh"
      },
      "source": [
        "clean_data = '/content/drive/MyDrive/Mini_project/cleaned_dataset.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhh3JYnwbqvx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCRYS9w1btOP"
      },
      "source": [
        "df = pd.read_csv(clean_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UuLtmRgcf8l"
      },
      "source": [
        "df.drop(df.index[1000:], inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "WgnOWv35GNDK",
        "outputId": "5495b529-4b36-42b3-fddb-07ae84efe266"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>Score</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>review_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>5</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>buy several vitality can dog food product find...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>1</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>product arrive labeled jumbo salt peanuts...th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>4</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>confection around century light pillowy citrus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Karl</td>\n",
              "      <td>2</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>look secret ingredient robitussin believe find...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>5</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>great taffy great price wide assortment yummy ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                       review_clean\n",
              "0   1  ...  buy several vitality can dog food product find...\n",
              "1   2  ...  product arrive labeled jumbo salt peanuts...th...\n",
              "2   3  ...  confection around century light pillowy citrus...\n",
              "3   4  ...  look secret ingredient robitussin believe find...\n",
              "4   5  ...  great taffy great price wide assortment yummy ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnnYgyyu6QkD"
      },
      "source": [
        "import multiprocessing\n",
        "\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3I7-PQDFXWh",
        "outputId": "f4b5fc69-710d-42b8-9ddd-6232bbbd2657"
      },
      "source": [
        "! pip install unidecode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWhdwsRbFRq9"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from re import sub\n",
        "import multiprocessing\n",
        "from unidecode import unidecode\n",
        "\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.test.utils import get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "\n",
        "from time import time \n",
        "from collections import defaultdict\n",
        "\n",
        "import logging  # Setting up the loggings to monitor gensim\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fc0s4U5ZeyRh"
      },
      "source": [
        "w2v_model = Word2Vec(min_count=3,\n",
        "                     window=4,\n",
        "                     size=300,\n",
        "                     sample=1e-5, \n",
        "                     alpha=0.03, \n",
        "                     min_alpha=0.0007, \n",
        "                     negative=20,\n",
        "                     workers=multiprocessing.cpu_count()-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "lT7tDRHkGEG2",
        "outputId": "ff2c9fe6-ca13-4e07-dd6c-de74190955d1"
      },
      "source": [
        "sent = [row for row in df.review_clean]\n",
        "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
        "bigram = Phraser(phrases)\n",
        "sentences = bigram[sent]\n",
        "sentences[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:04:23: collecting all words and their counts\n",
            "INFO - 17:04:23: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 17:04:24: collected 882 word types from a corpus of 233049 words (unigram + bigrams) and 1000 sentences\n",
            "INFO - 17:04:24: using 882 counts as vocab in Phrases<0 vocab, min_count=1, threshold=10.0, max_vocab_size=40000000>\n",
            "INFO - 17:04:24: source_vocab length 882\n",
            "INFO - 17:04:24: Phraser built with 1 phrasegrams\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'product arrive labeled jumbo salt peanuts...the peanut actually small size unsalted sure error vendor intend represent product jumbo'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLMSWmU6HAad",
        "outputId": "abd26cb7-0c8a-4c32-84bb-f4e8d7da4fb8"
      },
      "source": [
        "start = time()\n",
        "\n",
        "w2v_model.build_vocab(sentences, progress_per=50000)\n",
        "\n",
        "print('Time to build vocab: {} mins'.format(round((time() - start) / 60, 2)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:04:35: collecting all words and their counts\n",
            "WARNING - 17:04:35: Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "INFO - 17:04:35: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 17:04:35: collected 48 word types from a corpus of 233049 raw words and 1000 sentences\n",
            "INFO - 17:04:35: Loading a fresh vocabulary\n",
            "INFO - 17:04:35: effective_min_count=3 retains 43 unique words (89% of original 48, drops 5)\n",
            "INFO - 17:04:35: effective_min_count=3 leaves 233043 word corpus (99% of original 233049, drops 6)\n",
            "INFO - 17:04:35: deleting the raw counts dictionary of 48 items\n",
            "INFO - 17:04:35: sample=1e-05 downsamples 39 most-common words\n",
            "INFO - 17:04:35: downsampling leaves estimated 3747 word corpus (1.6% of prior 233043)\n",
            "INFO - 17:04:35: estimated required memory for 43 words and 300 dimensions: 124700 bytes\n",
            "INFO - 17:04:35: resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.0 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsHrVnZhHFol",
        "outputId": "34694798-1453-4d6e-8a31-595964ee9c73"
      },
      "source": [
        "start = time()\n",
        "\n",
        "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
        "\n",
        "print('Time to train the model: {} mins'.format(round((time() - start) / 60, 2)))\n",
        "\n",
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:04:54: training model with 1 workers on 43 vocabulary and 300 features, using sg=0 hs=0 sample=1e-05 negative=20 window=4\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 1 : training on 233049 raw words (3718 effective words) took 0.1s, 57044 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 2 : training on 233049 raw words (3717 effective words) took 0.0s, 76795 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 3 : training on 233049 raw words (3791 effective words) took 0.0s, 79793 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 4 : training on 233049 raw words (3729 effective words) took 0.0s, 77942 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 5 : training on 233049 raw words (3759 effective words) took 0.0s, 76342 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 6 : training on 233049 raw words (3757 effective words) took 0.1s, 72666 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 7 : training on 233049 raw words (3621 effective words) took 0.1s, 62934 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 8 : training on 233049 raw words (3831 effective words) took 0.1s, 73946 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 9 : training on 233049 raw words (3735 effective words) took 0.0s, 75044 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 10 : training on 233049 raw words (3925 effective words) took 0.1s, 70726 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 11 : training on 233049 raw words (3693 effective words) took 0.1s, 70962 effective words/s\n",
            "INFO - 17:04:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:54: EPOCH - 12 : training on 233049 raw words (3751 effective words) took 0.1s, 72374 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 13 : training on 233049 raw words (3683 effective words) took 0.1s, 69576 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 14 : training on 233049 raw words (3746 effective words) took 0.0s, 77856 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 15 : training on 233049 raw words (3814 effective words) took 0.1s, 75833 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 16 : training on 233049 raw words (3711 effective words) took 0.1s, 73671 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 17 : training on 233049 raw words (3691 effective words) took 0.1s, 72555 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 18 : training on 233049 raw words (3737 effective words) took 0.0s, 76546 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 19 : training on 233049 raw words (3714 effective words) took 0.0s, 78126 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 20 : training on 233049 raw words (3615 effective words) took 0.1s, 70395 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 21 : training on 233049 raw words (3755 effective words) took 0.0s, 79505 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 22 : training on 233049 raw words (3817 effective words) took 0.0s, 78032 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 23 : training on 233049 raw words (3685 effective words) took 0.1s, 68494 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 24 : training on 233049 raw words (3886 effective words) took 0.0s, 79747 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 25 : training on 233049 raw words (3681 effective words) took 0.0s, 75977 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 26 : training on 233049 raw words (3733 effective words) took 0.1s, 65924 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 27 : training on 233049 raw words (3790 effective words) took 0.1s, 71871 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 28 : training on 233049 raw words (3832 effective words) took 0.1s, 55699 effective words/s\n",
            "INFO - 17:04:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:55: EPOCH - 29 : training on 233049 raw words (3750 effective words) took 0.1s, 68556 effective words/s\n",
            "INFO - 17:04:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 17:04:56: EPOCH - 30 : training on 233049 raw words (3733 effective words) took 0.1s, 71093 effective words/s\n",
            "INFO - 17:04:56: training on a 6991470 raw words (112400 effective words) took 1.8s, 63316 effective words/s\n",
            "INFO - 17:04:56: precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to train the model: 0.03 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxvQxc7FHKiM",
        "outputId": "b2561a8b-279d-4dd6-edfe-8d7e5f582953"
      },
      "source": [
        "w2v_model.save(\"word2vec.model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:05:12: saving Word2Vec object under word2vec.model, separately None\n",
            "INFO - 17:05:12: not storing attribute vectors_norm\n",
            "INFO - 17:05:12: not storing attribute cum_table\n",
            "INFO - 17:05:12: saved word2vec.model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0TOBiHcHOFk"
      },
      "source": [
        "file_export = df.copy()\n",
        "file_export['old_text'] = file_export.review_clean\n",
        "file_export.old_text = file_export.old_text.str.join(' ')\n",
        "file_export.review_clean = file_export.review_clean.apply(lambda x: ' '.join(bigram[x]))\n",
        "file_export.Score = file_export.Score.astype('int8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxAeAXyEJD3h"
      },
      "source": [
        "file_export[['review_clean', 'Score']].to_csv('NEWcleaned_dataset.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cQg1A6VJTVg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NohUZTgq6hFa",
        "outputId": "67d7208f-921f-496e-8145-2ae2f78d4d75"
      },
      "source": [
        "word_vectors = Word2Vec.load(\"/content/word2vec.model\").wv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:11:10: loading Word2Vec object from /content/word2vec.model\n",
            "INFO - 17:11:10: loading wv recursively from /content/word2vec.model.wv.* with mmap=None\n",
            "INFO - 17:11:10: setting ignored attribute vectors_norm to None\n",
            "INFO - 17:11:10: loading vocabulary recursively from /content/word2vec.model.vocabulary.* with mmap=None\n",
            "INFO - 17:11:10: loading trainables recursively from /content/word2vec.model.trainables.* with mmap=None\n",
            "INFO - 17:11:10: setting ignored attribute cum_table to None\n",
            "INFO - 17:11:10: loaded /content/word2vec.model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dNcA8jmJdMB"
      },
      "source": [
        "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDs_kr5WJi54",
        "outputId": "13065772-f1d5-4c98-f59a-3531a9d314f9"
      },
      "source": [
        "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:11:49: precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(')', 0.9999358057975769),\n",
              " (':', 0.9999303817749023),\n",
              " (',', 0.9999246597290039),\n",
              " ('h', 0.9999146461486816),\n",
              " ('b', 0.9999127984046936),\n",
              " ('>', 0.9999083280563354),\n",
              " ('x', 0.9998899698257446),\n",
              " ('(', 0.9998859167098999),\n",
              " ('?', 0.9998849630355835),\n",
              " ('&', 0.999879777431488)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ut4jnImYJmx6"
      },
      "source": [
        "positive_cluster_index = 1\n",
        "positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
        "negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJldcZ-pJqt6"
      },
      "source": [
        "words = pd.DataFrame(word_vectors.vocab.keys())\n",
        "words.columns = ['words']\n",
        "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
        "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
        "words.cluster = words.cluster.apply(lambda x: x[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPVV5YQ6JwIR",
        "outputId": "7165c612-3f3e-47e1-ffff-4cd51b940e0c"
      },
      "source": [
        "words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
        "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
        "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 17:12:49: NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "ZUwIY6aSK1ts",
        "outputId": "acb495a7-f81b-41a9-f441-78e140371fed"
      },
      "source": [
        "\n",
        "words.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>vectors</th>\n",
              "      <th>cluster</th>\n",
              "      <th>cluster_value</th>\n",
              "      <th>closeness_score</th>\n",
              "      <th>sentiment_coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>[0.006674287, 0.07171218, -0.03071274, -0.0002...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>75.691398</td>\n",
              "      <td>75.691398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u</td>\n",
              "      <td>[0.0051192185, 0.07114216, -0.031233596, -0.00...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>57.512168</td>\n",
              "      <td>57.512168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>y</td>\n",
              "      <td>[0.0070375404, 0.0694881, -0.031878166, -0.001...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>80.184397</td>\n",
              "      <td>-80.184397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>[0.003566899, 0.07001784, -0.03069721, -0.0006...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>31.117832</td>\n",
              "      <td>31.117832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s</td>\n",
              "      <td>[0.007937334, 0.0684391, -0.033087328, -0.0025...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>49.617093</td>\n",
              "      <td>-49.617093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>e</td>\n",
              "      <td>[0.005335425, 0.06891587, -0.03138582, -0.0008...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>40.949991</td>\n",
              "      <td>40.949991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>v</td>\n",
              "      <td>[0.0073090238, 0.07023648, -0.03271517, -0.002...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>65.421151</td>\n",
              "      <td>-65.421151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>r</td>\n",
              "      <td>[0.007818953, 0.07156993, -0.031813942, -0.000...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>56.382018</td>\n",
              "      <td>56.382018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a</td>\n",
              "      <td>[0.0071994313, 0.069396086, -0.03263359, -0.00...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>63.168262</td>\n",
              "      <td>-63.168262</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>l</td>\n",
              "      <td>[0.0069516073, 0.06933905, -0.03215307, -0.001...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>90.602353</td>\n",
              "      <td>-90.602353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  words  ... sentiment_coeff\n",
              "0     b  ...       75.691398\n",
              "1     u  ...       57.512168\n",
              "2     y  ...      -80.184397\n",
              "3        ...       31.117832\n",
              "4     s  ...      -49.617093\n",
              "5     e  ...       40.949991\n",
              "6     v  ...      -65.421151\n",
              "7     r  ...       56.382018\n",
              "8     a  ...      -63.168262\n",
              "9     l  ...      -90.602353\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPyKHN_ULXbo"
      },
      "source": [
        "words[['words', 'sentiment_coeff']].to_csv('sentiment_dictionary.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_2C91IoLbET"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "from IPython.display import display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePifnwafLzea"
      },
      "source": [
        "final_file = pd.read_csv('/content/NEWcleaned_dataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vDD_SEXQN7JY",
        "outputId": "0c2aa5ea-6eed-4b7a-c27c-197d54b75ea5"
      },
      "source": [
        "final_file.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_clean</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b u y   s e v e r a l   v i t a l i t y   c a ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p r o d u c t   a r r i v e   l a b e l e d   ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>c o n f e c t i o n   a r o u n d   c e n t u ...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>l o o k   s e c r e t   i n g r e d i e n t   ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>g r e a t   t a f f y   g r e a t   p r i c e ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        review_clean  Score\n",
              "0  b u y   s e v e r a l   v i t a l i t y   c a ...      5\n",
              "1  p r o d u c t   a r r i v e   l a b e l e d   ...      1\n",
              "2  c o n f e c t i o n   a r o u n d   c e n t u ...      4\n",
              "3  l o o k   s e c r e t   i n g r e d i e n t   ...      2\n",
              "4  g r e a t   t a f f y   g r e a t   p r i c e ...      5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CxZyAMEL4s0"
      },
      "source": [
        "sentiment_map = pd.read_csv('/content/sentiment_dictionary.csv')\n",
        "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "A1rVWagKNtgY",
        "outputId": "fa0ef2e2-b9c9-47f7-8ddd-a8192ba0b577"
      },
      "source": [
        "sentiment_map.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>words</th>\n",
              "      <th>sentiment_coeff</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>b</td>\n",
              "      <td>75.691398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>u</td>\n",
              "      <td>57.512168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>y</td>\n",
              "      <td>-80.184397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td></td>\n",
              "      <td>31.117832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s</td>\n",
              "      <td>-49.617093</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  words  sentiment_coeff\n",
              "0     b        75.691398\n",
              "1     u        57.512168\n",
              "2     y       -80.184397\n",
              "3              31.117832\n",
              "4     s       -49.617093"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGaALszZL-x-"
      },
      "source": [
        "file_weighting = final_file.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7r9epZaMCzN",
        "outputId": "03918345-b6ff-4914-f800-7d0237e8739f"
      },
      "source": [
        "tfidf = TfidfVectorizer(tokenizer=lambda y: y.split(), norm=None)\n",
        "tfidf.fit(file_weighting.review_clean)\n",
        "features = pd.Series(tfidf.get_feature_names())\n",
        "transformed = tfidf.transform(file_weighting.review_clean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quM23MtTMZ7_"
      },
      "source": [
        "def create_tfidf_dictionary(x, transformed_file, features):\n",
        "    '''\n",
        "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
        "    \n",
        "    inspired  by function from this wonderful article: \n",
        "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
        "    \n",
        "    x - row of dataframe, containing sentences, and their indexes,\n",
        "    transformed_file - all sentences transformed with TfidfVectorizer\n",
        "    features - names of all words in corpus used in TfidfVectorizer\n",
        "\n",
        "    '''\n",
        "    vector_coo = transformed_file[x.name].tocoo()\n",
        "    vector_coo.col = features.iloc[vector_coo.col].values\n",
        "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
        "    return dict_from_coo\n",
        "\n",
        "def replace_tfidf_words(x, transformed_file, features):\n",
        "    '''\n",
        "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
        "    x - row of dataframe, containing sentences, and their indexes,\n",
        "    transformed_file - all sentences transformed with TfidfVectorizer\n",
        "    features - names of all words in corpus used in TfidfVectorizer\n",
        "    '''\n",
        "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
        "    return list(map(lambda y:dictionary[f'{y}'], x.review_clean.split()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7gAkJa_MuTF",
        "outputId": "0d259930-c9ec-460b-8088-016112b7df49"
      },
      "source": [
        "%%time\n",
        "replaced_tfidf_scores = file_weighting.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 418 ms, sys: 8.49 ms, total: 427 ms\n",
            "Wall time: 422 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7WjzbrQNiM3"
      },
      "source": [
        "def replace_sentiment_words(word, sentiment_dict):\n",
        "    '''\n",
        "    replacing each word with its associated sentiment score from sentiment dict\n",
        "    '''\n",
        "    try:\n",
        "        out = sentiment_dict[word]\n",
        "    except KeyError:\n",
        "        out = 0\n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul7j8gHFNjf3"
      },
      "source": [
        "replaced_closeness_scores = file_weighting.review_clean.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fM7S9oSNpeK"
      },
      "source": [
        "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, file_weighting.review_clean, file_weighting.Score]).T\n",
        "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence', 'sentiment']\n",
        "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
        "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
        "replacement_df['sentiment'] = [1 if i==1 else 0 for i in replacement_df.sentiment]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "y6Ktqm7cOmCw",
        "outputId": "23e60c0e-1a68-4601-ed13-209edabd1e24"
      },
      "source": [
        "predicted_classes = replacement_df.prediction\n",
        "y_test = replacement_df.sentiment\n",
        "\n",
        "conf_matrix = pd.DataFrame(confusion_matrix(replacement_df.sentiment, replacement_df.prediction))\n",
        "print('Confusion Matrix')\n",
        "display(conf_matrix)\n",
        "\n",
        "test_scores = accuracy_score(y_test,predicted_classes), precision_score(y_test, predicted_classes), recall_score(y_test, predicted_classes), f1_score(y_test, predicted_classes)\n",
        "\n",
        "print('\\n \\n Scores')\n",
        "scores = pd.DataFrame(data=[test_scores])\n",
        "scores.columns = ['accuracy', 'precision', 'recall', 'f1']\n",
        "scores = scores.T\n",
        "scores.columns = ['scores']\n",
        "display(scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>840</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>93</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0   1\n",
              "0  840  62\n",
              "1   93   5"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " \n",
            " Scores\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scores</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.845000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precision</th>\n",
              "      <td>0.074627</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>recall</th>\n",
              "      <td>0.051020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>f1</th>\n",
              "      <td>0.060606</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             scores\n",
              "accuracy   0.845000\n",
              "precision  0.074627\n",
              "recall     0.051020\n",
              "f1         0.060606"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}